{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1d81e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dictionary_corpus\n",
    "from dictionary_corpus import Corpus\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, SparsePCA, KernelPCA, IncrementalPCA\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import os\n",
    "out_dir = 'contextual_embeddings'\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "matplotlib.use('webagg')\n",
    "types = ['c0','h0','c1','h1']\n",
    "# load the model and the corpus\n",
    "model = torch.load('hidden650_batch128_dropout0.2_lr20.0.pt',map_location=torch.device('cpu'))\n",
    "corpus = Corpus('')\n",
    "# print(\"Vocab size %d\", ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3b9b2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(x,y):\n",
    "        dist = np.linalg.norm(x-y)\n",
    "        return dist.round(2)\n",
    "def cos(x,y):\n",
    "    dist = np.dot(x,y)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "    return dist.round(2)\n",
    "\n",
    "def modulated_word_heat(d0,tar:str):\n",
    "    # assuming the input has 5 columns: tensor labels file prev target, the index is a unique integer\n",
    "    df = d0.where(d0['target']==tar).dropna().drop(['labels','target'],axis=1)\n",
    "    df['tmp'] = df.index\n",
    "    df['id'] =  df['tmp'].apply(lambda x: str(x)+'_')+df['prev'] + df['file'].apply(lambda x: '_'+str(x))\n",
    "    df = df.drop(['prev','file'],axis=1)\n",
    "    for word in df.index:\n",
    "        col = df.loc[word]['id']\n",
    "        df[col] = df['tensors'].apply(lambda x: euclidean(x,df.loc[word]['tensors']))\n",
    "    return df.drop(['tensors','tmp'],axis=1).set_index('id')\n",
    "\n",
    "def all_mod_heat(d0,words: list):\n",
    "    def check(x):\n",
    "        if x in words:\n",
    "            return x\n",
    "        else:\n",
    "            return np.nan\n",
    "    # assuming the input has 5 columns: tensor labels file prev target, the index is a unique integer \n",
    "    df = d0.copy()\n",
    "    df['tmp'] = df.index\n",
    "    df['id'] =  df['tmp'].apply(lambda x: str(x)+'_')+df['prev']+' '+df['target'] + df['file'].apply(lambda x: '_'+str(x))\n",
    "    df['sort'] = df['target']+df['file']\n",
    "    df['v']=df['file'].apply(lambda x: int(x))\n",
    "    \n",
    "    df = df.sort_values(by='sort')\n",
    "    df['target'] = df['target'].apply(lambda x: check(x))\n",
    "    df = df.dropna()\n",
    "#     print(d3.shape)\n",
    "    df = df.drop(['prev','file','target','tmp','labels','sort','v'],axis=1)\n",
    "    for idx in tqdm(df.index):\n",
    "        col = df.loc[idx]['id']\n",
    "        df[col] = df['tensors'].apply(lambda x: euclidean(x,df.loc[idx]['tensors']))\n",
    "    return df.drop(['tensors'],axis=1).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "c69c86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict = {}\n",
    "for i in types:\n",
    "    with open(f'{out_dir}/all_sent_{i}','rb') as f:\n",
    "        embed_dict[i] = pk.load(f)\n",
    "\n",
    "def l2_normalisation(embed_dict,types=types):\n",
    "    l2 = {}\n",
    "    for t in types:\n",
    "        l2[t] = np.linalg.norm(embed_dict[t]['tensors'].agg('mean'))\n",
    "        embed_dict[t]['tensors'] = embed_dict[t]['tensors']/l2[t]\n",
    "    return embed_dict\n",
    "l2_normalised_embed_dict = l2_normalisation(embed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "02e8e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_type_word_dist(df,extraction_type):\n",
    "    #four embedding is a dict key = c0 h0 c1 h1, val =  6 columns\n",
    "    res = {}\n",
    "    for word,dfx in df.groupby(by='target'):\n",
    "        if word == 'went':\n",
    "            continue\n",
    "        dfa = dfx[dfx['file']=='1']\n",
    "        dfb = dfx[dfx['file']=='2']\n",
    "        x1 = dfa['tensors'].agg('mean')\n",
    "        x2 = dfb['tensors'].agg('mean')\n",
    "        res[word] = euclidean(x1,x2)\n",
    "    file_dis = pd.DataFrame.from_dict(res, orient='index',columns = [f'file_dist_{extraction_type}']).reset_index().rename(columns={\"index\": \"target\"})\n",
    "    return file_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e22fc709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_types_of_dist(embed_dict,types = types, normalised=False):\n",
    "    for t in types:\n",
    "        delta_df = single_type_word_dist(embed_dict[t],t)\n",
    "        if t == 'c0':\n",
    "            df = delta_df\n",
    "        else:\n",
    "            df = pd.merge(df,delta_df, on='target')\n",
    "    if normalised == True:\n",
    "        l2 = {}\n",
    "        for t in types:\n",
    "            l2[t] = np.linalg.norm(embed_dict[t]['tensors'].agg('mean'))\n",
    "            df[f'file_dist_{t}'] = (df[f'file_dist_{t}']/l2[t]).apply(lambda x:round(x,2))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "21503b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_dist_c0</th>\n",
       "      <th>file_dist_h0</th>\n",
       "      <th>file_dist_c1</th>\n",
       "      <th>file_dist_h1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Switzerland</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <td>0.66</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>1.19</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>1.10</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can</th>\n",
       "      <td>1.04</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thought</th>\n",
       "      <td>1.14</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomatoes</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transistor</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>1.17</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>1.17</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_dist_c0  file_dist_h0  file_dist_c1  file_dist_h1\n",
       "target                                                             \n",
       "Switzerland          0.42          0.92          0.50          0.79\n",
       "bank                 0.66          1.34          1.28          2.10\n",
       "book                 1.19          2.12          1.57          1.98\n",
       "books                1.10          2.04          1.44          1.83\n",
       "can                  1.04          1.94          1.26          1.64\n",
       "...                   ...           ...           ...           ...\n",
       "thought              1.14          2.55          1.51          1.98\n",
       "tomatoes             0.50          0.94          0.78          1.13\n",
       "transistor           0.46          0.87          0.51          0.86\n",
       "watch                1.17          2.42          1.91          2.32\n",
       "wind                 1.17          2.24          1.63          2.53\n",
       "\n",
       "[31 rows x 4 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_types_dist_all_words = four_types_of_dist(embed_dict, normalised=True).set_index('target')\n",
    "four_types_dist_all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5fd5b",
   "metadata": {},
   "source": [
    "# DF1 is emb of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9ab95977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>692_a_2</th>\n",
       "      <th>693_little_2</th>\n",
       "      <th>694_wild_2</th>\n",
       "      <th>695_a_2</th>\n",
       "      <th>696_odd_2</th>\n",
       "      <th>697_sitting_2</th>\n",
       "      <th>698_a_2</th>\n",
       "      <th>699_last_2</th>\n",
       "      <th>700_a_2</th>\n",
       "      <th>701_a_2</th>\n",
       "      <th>702_the_2</th>\n",
       "      <th>703_rubber_2</th>\n",
       "      <th>704_black_2</th>\n",
       "      <th>705_dead_2</th>\n",
       "      <th>706_a_2</th>\n",
       "      <th>...</th>\n",
       "      <th>1074_the_1</th>\n",
       "      <th>1075_the_1</th>\n",
       "      <th>1076_of_1</th>\n",
       "      <th>1077_crispy_1</th>\n",
       "      <th>1078_her_1</th>\n",
       "      <th>1079_whole_1</th>\n",
       "      <th>1080_and_1</th>\n",
       "      <th>1081_of_1</th>\n",
       "      <th>1082_roasted_1</th>\n",
       "      <th>1083_fried_1</th>\n",
       "      <th>1084_roast_1</th>\n",
       "      <th>1085_or_1</th>\n",
       "      <th>1086_the_1</th>\n",
       "      <th>1087_,_1</th>\n",
       "      <th>1088_,_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692_a_2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.54</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.89</td>\n",
       "      <td>5.69</td>\n",
       "      <td>4.04</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.36</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.45</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.68</td>\n",
       "      <td>...</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.55</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.36</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.43</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.81</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693_little_2</th>\n",
       "      <td>5.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.97</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.65</td>\n",
       "      <td>4.14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.66</td>\n",
       "      <td>3.83</td>\n",
       "      <td>4.48</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5.58</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.38</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694_wild_2</th>\n",
       "      <td>5.54</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.82</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.74</td>\n",
       "      <td>...</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.27</td>\n",
       "      <td>4.39</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695_a_2</th>\n",
       "      <td>4.70</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.55</td>\n",
       "      <td>3.37</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.41</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.66</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.21</td>\n",
       "      <td>6.04</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696_odd_2</th>\n",
       "      <td>4.89</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3.28</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.34</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.53</td>\n",
       "      <td>...</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.40</td>\n",
       "      <td>6.35</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.59</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.75</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084_roast_1</th>\n",
       "      <td>4.78</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.84</td>\n",
       "      <td>5.45</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.69</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.87</td>\n",
       "      <td>...</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.46</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.85</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.53</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.55</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085_or_1</th>\n",
       "      <td>4.81</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.93</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.94</td>\n",
       "      <td>5.75</td>\n",
       "      <td>4.49</td>\n",
       "      <td>5.43</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.99</td>\n",
       "      <td>...</td>\n",
       "      <td>4.78</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.14</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.87</td>\n",
       "      <td>5.13</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086_the_1</th>\n",
       "      <td>5.25</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.69</td>\n",
       "      <td>4.68</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.36</td>\n",
       "      <td>...</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087_,_1</th>\n",
       "      <td>5.48</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5.51</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.96</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.79</td>\n",
       "      <td>6.03</td>\n",
       "      <td>5.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.65</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.86</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.48</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.18</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088_,_1</th>\n",
       "      <td>4.83</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.83</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.44</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.25</td>\n",
       "      <td>...</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.18</td>\n",
       "      <td>5.13</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.54</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.78</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              692_a_2  693_little_2  694_wild_2  695_a_2  696_odd_2  \\\n",
       "id                                                                    \n",
       "692_a_2          0.00          5.16        5.54     4.70       4.89   \n",
       "693_little_2     5.16          0.00        4.32     4.18       3.95   \n",
       "694_wild_2       5.54          4.32        0.00     4.83       4.82   \n",
       "695_a_2          4.70          4.18        4.83     0.00       4.03   \n",
       "696_odd_2        4.89          3.95        4.82     4.03       0.00   \n",
       "...               ...           ...         ...      ...        ...   \n",
       "1084_roast_1     4.78          4.29        4.77     4.79       4.84   \n",
       "1085_or_1        4.81          5.03        4.93     5.11       4.94   \n",
       "1086_the_1       5.25          4.38        4.45     4.52       4.75   \n",
       "1087_,_1         5.48          5.66        5.77     5.51       6.02   \n",
       "1088_,_1         4.83          5.09        5.00     5.12       5.34   \n",
       "\n",
       "              697_sitting_2  698_a_2  699_last_2  700_a_2  701_a_2  702_the_2  \\\n",
       "id                                                                              \n",
       "692_a_2                5.69     4.04        5.23     4.97     4.36       5.38   \n",
       "693_little_2           4.97     3.99        4.14     4.57     4.31       4.65   \n",
       "694_wild_2             5.44     4.62        4.58     4.88     4.64       4.54   \n",
       "695_a_2                4.55     3.37        4.33     3.57     3.41       4.76   \n",
       "696_odd_2              4.10     3.28        4.55     4.34     3.49       4.75   \n",
       "...                     ...      ...         ...      ...      ...        ...   \n",
       "1084_roast_1           5.45     4.33        5.16     5.30     4.69       5.26   \n",
       "1085_or_1              5.75     4.49        5.43     5.50     4.98       5.62   \n",
       "1086_the_1             5.69     4.68        5.06     5.03     4.64       4.44   \n",
       "1087_,_1               6.25     5.39        5.96     5.94     5.79       6.03   \n",
       "1088_,_1               5.83     4.53        5.39     5.44     5.05       5.23   \n",
       "\n",
       "              703_rubber_2  704_black_2  705_dead_2  706_a_2  ...  1074_the_1  \\\n",
       "id                                                            ...               \n",
       "692_a_2               4.44         5.45        4.60     4.68  ...        4.14   \n",
       "693_little_2          4.12         4.04        3.65     4.14  ...        4.44   \n",
       "694_wild_2            4.92         4.57        4.23     4.74  ...        5.11   \n",
       "695_a_2               4.05         4.66        3.36     2.50  ...        4.81   \n",
       "696_odd_2             4.16         4.45        3.39     3.53  ...        4.70   \n",
       "...                    ...          ...         ...      ...  ...         ...   \n",
       "1084_roast_1          4.46         5.01        4.56     4.87  ...        4.64   \n",
       "1085_or_1             5.19         5.30        4.71     4.99  ...        4.78   \n",
       "1086_the_1            4.82         4.64        4.57     4.36  ...        4.38   \n",
       "1087_,_1              5.73         6.26        5.65     5.75  ...        5.39   \n",
       "1088_,_1              5.05         5.64        5.23     5.25  ...        4.71   \n",
       "\n",
       "              1075_the_1  1076_of_1  1077_crispy_1  1078_her_1  1079_whole_1  \\\n",
       "id                                                                             \n",
       "692_a_2             5.14       5.55           4.90        4.36          5.28   \n",
       "693_little_2        4.09       4.66           3.83        4.48          3.84   \n",
       "694_wild_2          4.82       4.69           4.50        5.27          4.39   \n",
       "695_a_2             4.55       4.56           4.14        4.63          4.21   \n",
       "696_odd_2           4.62       4.77           3.77        4.49          4.40   \n",
       "...                  ...        ...            ...         ...           ...   \n",
       "1084_roast_1        4.50       5.46           4.49        4.85          5.03   \n",
       "1085_or_1           5.32       5.14           4.54        4.87          5.13   \n",
       "1086_the_1          4.58       4.93           4.48        4.55          4.63   \n",
       "1087_,_1            5.86       5.60           5.36        5.48          5.76   \n",
       "1088_,_1            5.18       5.13           4.49        4.70          5.30   \n",
       "\n",
       "              1080_and_1  1081_of_1  1082_roasted_1  1083_fried_1  \\\n",
       "id                                                                  \n",
       "692_a_2             5.67       5.43            4.94          4.63   \n",
       "693_little_2        5.58       4.92            4.21          4.04   \n",
       "694_wild_2          5.91       5.06            4.72          4.96   \n",
       "695_a_2             6.04       4.87            4.48          4.70   \n",
       "696_odd_2           6.35       5.39            4.59          4.77   \n",
       "...                  ...        ...             ...           ...   \n",
       "1084_roast_1        5.53       5.01            4.48          4.14   \n",
       "1085_or_1           4.96       4.35            4.77          4.88   \n",
       "1086_the_1          5.50       4.14            4.63          4.48   \n",
       "1087_,_1            5.38       4.46            5.64          5.18   \n",
       "1088_,_1            5.54       4.85            4.89          4.51   \n",
       "\n",
       "              1084_roast_1  1085_or_1  1086_the_1  1087_,_1  1088_,_1  \n",
       "id                                                                     \n",
       "692_a_2               4.78       4.81        5.25      5.48      4.83  \n",
       "693_little_2          4.29       5.03        4.38      5.66      5.09  \n",
       "694_wild_2            4.77       4.93        4.45      5.77      5.00  \n",
       "695_a_2               4.79       5.11        4.52      5.51      5.12  \n",
       "696_odd_2             4.84       4.94        4.75      6.02      5.34  \n",
       "...                    ...        ...         ...       ...       ...  \n",
       "1084_roast_1          0.00       4.75        4.55      5.38      4.57  \n",
       "1085_or_1             4.75       0.00        4.80      4.75      4.78  \n",
       "1086_the_1            4.55       4.80        0.00      5.41      5.03  \n",
       "1087_,_1              5.38       4.75        5.41      0.00      4.02  \n",
       "1088_,_1              4.57       4.78        5.03      4.02      0.00  \n",
       "\n",
       "[39 rows x 39 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = embed_dicts['h1'].copy()\n",
    "wh = modulated_word_heat(df1,'duck')\n",
    "wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0b90c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = np.zeros_like(wh)\n",
    "mask1[np.triu_indices_from(mask1)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1471d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))# plot heatmap\n",
    "sns.heatmap(wh,vmin=2,vmax=10,mask=mask1)\n",
    "plt.title(f'heat within {3}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34db4f",
   "metadata": {},
   "source": [
    "# Single word experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "fc3554ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'moves'\n",
    "four_types_target_embeddings = {}\n",
    "for t in types:\n",
    "    df = l2_normalised_embed_dict[t]\n",
    "    four_types_target_embeddings[t] = df[df['target']==target].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "3bb544e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_dist_c0    1.12\n",
       "file_dist_h0    2.49\n",
       "file_dist_c1    1.52\n",
       "file_dist_h1    2.06\n",
       "Name: moves, dtype: float64"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_dist = four_types_dist_all_words.loc['moves']\n",
    "wind_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ec656a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<00:00, 217.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<00:00, 213.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<00:00, 215.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<00:00, 214.98it/s]\n"
     ]
    }
   ],
   "source": [
    "heat_data_list = []\n",
    "for i in types:\n",
    "    heat_data = all_mod_heat(four_types_target_embeddings[i],[target])\n",
    "    heat_data_list.append(heat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "bfb5fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "c8f22343",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_d = np.zeros_like(heat_data_list[0])\n",
    "mask_d[np.triu_indices_from(mask_d)] = True\n",
    "f, axes = plt.subplots(2,2,figsize=(6, 6))\n",
    "axes[0][0].set_title(f'{target} c0')\n",
    "axes[0][1].set_title(f'{target} h0')\n",
    "axes[1][0].set_title(f'{target} c1')\n",
    "axes[1][1].set_title(f'{target} h1')\n",
    "sns.heatmap(heat_data_list[0],vmin=1,vmax=4,xticklabels=False,mask=mask_d,ax=axes[0][0])\n",
    "sns.heatmap(heat_data_list[1],vmin=1,vmax=4,xticklabels=False, yticklabels=False, mask=mask_d,ax=axes[0][1])\n",
    "sns.heatmap(heat_data_list[2],vmin=1,vmax=4,xticklabels=False, yticklabels=False, mask=mask_d,ax=axes[1][0])\n",
    "sns.heatmap(heat_data_list[3],vmin=1,vmax=4,xticklabels=False, yticklabels=False, mask=mask_d,ax=axes[1][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e33812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7713af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
