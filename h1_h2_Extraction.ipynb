{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d81e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezio/.cache/pypoetry/virtualenvs/polysemy-EBh2Gjjb-py3.7/lib/python3.7/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'model.RNNModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ezio/.cache/pypoetry/virtualenvs/polysemy-EBh2Gjjb-py3.7/lib/python3.7/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ezio/.cache/pypoetry/virtualenvs/polysemy-EBh2Gjjb-py3.7/lib/python3.7/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ezio/.cache/pypoetry/virtualenvs/polysemy-EBh2Gjjb-py3.7/lib/python3.7/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ezio/.cache/pypoetry/virtualenvs/polysemy-EBh2Gjjb-py3.7/lib/python3.7/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dictionary_corpus\n",
    "from dictionary_corpus import Corpus\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, SparsePCA, KernelPCA, IncrementalPCA\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import os\n",
    "types= ['h1','h2']\n",
    "out_dir = 'contextual_embeddings/'\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "matplotlib.use('webagg')\n",
    "# load the model and the corpus\n",
    "model = torch.load('hidden650_batch128_dropout0.2_lr20.0.pt',map_location=torch.device('cpu'))\n",
    "corpus = Corpus('')\n",
    "# print(\"Vocab size %d\", ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b9b2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(x,y):\n",
    "        dist = np.linalg.norm(x-y)\n",
    "        return dist.round(2)\n",
    "def cos(x,y):\n",
    "    dist = np.dot(x,y)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "    return dist.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2271ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_feature_extraction(sent,target_word,file_type, model=model, corpus=corpus, which='h1'): \n",
    "    with torch.no_grad():\n",
    "        words = sent.split()\n",
    "        tokenized_sent=[]\n",
    "        for word in words:\n",
    "            if word in corpus.dictionary.word2idx.keys():\n",
    "                wordidx = corpus.dictionary.word2idx[word]\n",
    "            else:\n",
    "                #print(f'{word} is to be deleted')\n",
    "                wordidx = corpus.dictionary.word2idx['<unk>']\n",
    "            tokenized_sent.append(wordidx)\n",
    "        # initailize the hidden state of the model\n",
    "        hidden = model.init_hidden(1)\n",
    "        # iterate through the whole sentence\n",
    "        for i, wordid in enumerate(tokenized_sent):\n",
    "            word = corpus.dictionary.idx2word[wordid]\n",
    "            # we are not gonna use the output\n",
    "            _,hidden,emb= model(torch.as_tensor(wordid).reshape(1,1),hidden)\n",
    "            # the hidden embedding is the embedding we wanted.\n",
    "            # four of them correposinding to h0 h1 c0 c1\n",
    "            if i ==len(tokenized_sent):\n",
    "                print(f'{target} not in sentence {sent}_{file_type}, please check')\n",
    "            if word == target_word:\n",
    "                if which == types[0]:\n",
    "                    hidden_embedding = hidden[0][0].view(650).numpy()  \n",
    "                if which == types[1]:\n",
    "                    hidden_embedding = hidden[0][1].view(650).numpy() # so this is actually the output 650 vector\n",
    "                if which =='c0':\n",
    "                    hidden_embedding = hidden[1][0].view(650).numpy() \n",
    "                if which == 'c1':\n",
    "                    hidden_embedding = hidden[1][1].view(650).numpy()\n",
    "                if which == 'emb':\n",
    "                    hidden_embedding = emb.view(650).numpy()\n",
    "                df = {'label':words[i-1]+' '+target_word+file_type,'tensor':hidden_embedding}\n",
    "                return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a34d032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_features(file,model=model,which='h1'):\n",
    "    if '_' not in file:\n",
    "        print('wrong file name.')\n",
    "        exit()\n",
    "    # file name must be in the form of chicken_0_animal.txt\n",
    "    # because 'data/' are literally 5 charactes \n",
    "    tmp = file[5:] \n",
    "    target_word = tmp.split('_')[0]\n",
    "    file_type = tmp.split('_')[1]\n",
    "    # get tar word features from sentences in a file containing lines of sentences\n",
    "    d = {'tensors':[],'labels':[]}\n",
    "    with open(file,'r') as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if len(line)<3:\n",
    "            # if line is not a sentence, continue\n",
    "                continue\n",
    "            else:\n",
    "            # extract the features of the sentence return df\n",
    "                sent_feature = sent_feature_extraction(line,target_word,file_type,which=which)\n",
    "                d['tensors'].append(sent_feature['tensor'])\n",
    "                d['labels'].append(sent_feature['label'])\n",
    "        df = pd.DataFrame.from_dict(d)\n",
    "        df['file'] = df['labels'].apply(lambda x: x.split(' ')[1][-1])\n",
    "        df['prev'] = df['labels'].apply(lambda x: x.split(' ')[0])\n",
    "        df['target'] = df['labels'].apply(lambda x: x.split(' ')[1][:-1])\n",
    "        df = df.sort_values(by = 'target').reset_index().drop(['index'],axis=1)\n",
    "        if i==0:\n",
    "            raise NameError(f'{file} is a file that has no content')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6202ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_target_features('data/bank_1_ins.txt','c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3183acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_file(directory='data',out_dir='contextual_embeddings',types=types):\n",
    "# iterate over files in that directory\n",
    "    for i in types:\n",
    "        df = pd.DataFrame()\n",
    "        for filename in tqdm(os.listdir(directory)):\n",
    "            f = os.path.join(directory, filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(f):\n",
    "                delta_df = get_target_features(f,which = i)\n",
    "                df = pd.concat([df,delta_df])          \n",
    "            else:\n",
    "                continue\n",
    "        df = df.reset_index().drop(['index'],axis=1)\n",
    "        with open(f'{out_dir}/all_sent_{i}','wb') as f:\n",
    "            pk.dump(df,f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99cf58e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 64/64 [00:47<00:00,  1.35it/s]\n",
      "100%|███████████████████████████████████████████| 64/64 [00:55<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "extract_all_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b2d917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_sent_h1  all_sent_h2\r\n"
     ]
    }
   ],
   "source": [
    "!ls contextual_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "beee9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{out_dir}/all_sent_c0','rb') as f:\n",
    "#     c0 = pk.load(f)\n",
    "# with open(f'{out_dir}/all_sent_c1','rb') as f:\n",
    "#     c1 = pk.load(f)\n",
    "with open(f'{out_dir}/all_sent_{types[0]}','rb') as f:\n",
    "    h1 = pk.load(f)\n",
    "with open(f'{out_dir}/all_sent_{types[1]}','rb') as f:\n",
    "    h2 = pk.load(f)\n",
    "# pre processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7980fd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tensors</th>\n",
       "      <th>labels</th>\n",
       "      <th>file</th>\n",
       "      <th>prev</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.018521532, 0.045597155, 0.002335213, -0.058...</td>\n",
       "      <td>Looks like2</td>\n",
       "      <td>2</td>\n",
       "      <td>Looks</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.07884548, 0.033203643, 0.01734861, -0.12496...</td>\n",
       "      <td>yourself like2</td>\n",
       "      <td>2</td>\n",
       "      <td>yourself</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0039849347, 0.016776048, 0.024410218, -0.02...</td>\n",
       "      <td>support like2</td>\n",
       "      <td>2</td>\n",
       "      <td>support</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.11227927, 0.03317975, 0.001646313, -0.10016...</td>\n",
       "      <td>OS like2</td>\n",
       "      <td>2</td>\n",
       "      <td>OS</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.007854236, 0.0059105917, 0.009929255, -0.06...</td>\n",
       "      <td>around like2</td>\n",
       "      <td>2</td>\n",
       "      <td>around</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>[0.043512758, 0.4072944, 0.035686746, 0.064607...</td>\n",
       "      <td>glass door1</td>\n",
       "      <td>1</td>\n",
       "      <td>glass</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>[0.0052277055, 0.12090539, -0.0071009444, 0.11...</td>\n",
       "      <td>a door1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>[0.006641631, 0.0688867, 0.017595066, -0.02978...</td>\n",
       "      <td>their door1</td>\n",
       "      <td>1</td>\n",
       "      <td>their</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>[-0.00979613, 0.1276253, 0.021119574, -0.03380...</td>\n",
       "      <td>my door1</td>\n",
       "      <td>1</td>\n",
       "      <td>my</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>[0.014402006, 0.1687622, -0.019405259, 0.05822...</td>\n",
       "      <td>the door1</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1169 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tensors          labels file  \\\n",
       "0     [0.018521532, 0.045597155, 0.002335213, -0.058...     Looks like2    2   \n",
       "1     [0.07884548, 0.033203643, 0.01734861, -0.12496...  yourself like2    2   \n",
       "2     [0.0039849347, 0.016776048, 0.024410218, -0.02...   support like2    2   \n",
       "3     [0.11227927, 0.03317975, 0.001646313, -0.10016...        OS like2    2   \n",
       "4     [0.007854236, 0.0059105917, 0.009929255, -0.06...    around like2    2   \n",
       "...                                                 ...             ...  ...   \n",
       "1164  [0.043512758, 0.4072944, 0.035686746, 0.064607...     glass door1    1   \n",
       "1165  [0.0052277055, 0.12090539, -0.0071009444, 0.11...         a door1    1   \n",
       "1166  [0.006641631, 0.0688867, 0.017595066, -0.02978...     their door1    1   \n",
       "1167  [-0.00979613, 0.1276253, 0.021119574, -0.03380...        my door1    1   \n",
       "1168  [0.014402006, 0.1687622, -0.019405259, 0.05822...       the door1    1   \n",
       "\n",
       "          prev target  \n",
       "0        Looks   like  \n",
       "1     yourself   like  \n",
       "2      support   like  \n",
       "3           OS   like  \n",
       "4       around   like  \n",
       "...        ...    ...  \n",
       "1164     glass   door  \n",
       "1165         a   door  \n",
       "1166     their   door  \n",
       "1167        my   door  \n",
       "1168       the   door  \n",
       "\n",
       "[1169 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5fb727ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Switzerland', 'bank', 'book', 'books', 'can', 'chicken', 'computer', 'dates', 'door', 'duck', 'even', 'fish', 'form', 'lamb', 'like', 'line', 'mistakes', 'moves', 'pencil', 'potato', 'power', 'pupil', 'questions', 'rock', 'salmon', 'tears', 'thought', 'tomatoes', 'transistor', 'watch', 'went', 'wind']\n"
     ]
    }
   ],
   "source": [
    "l= []\n",
    "for key, g in h1.groupby(by='target'):\n",
    "    l.append(key)\n",
    "#     print(key=='went' or key=='line')\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59a8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
